{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "13pL--6rycN3"
   },
   "source": [
    "## Homework01: Three headed network in PyTorch\n",
    "\n",
    "This notebook accompanies the [week02 seminar](https://github.com/ml-mipt/ml-mipt/blob/advanced/week02_CNN_n_Vanishing_gradient/week02_CNN_for_texts.ipynb). Refer to that notebook for more comments.\n",
    "\n",
    "All the preprocessing is the same as in the classwork. *Including the data leakage in the train test split (it's still for bonus points).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P8zS7m-gycN5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import nltk\n",
    "import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have already downloaded the data on the Seminar, simply run through the next cells. Otherwise uncomment the next cell (and comment the another one ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  119M  100  119M    0     0  4351k      0  0:00:28  0:00:28 --:--:-- 4758k\n",
      "Train_rev1.csv\n",
      "--2020-03-25 02:42:12--  https://raw.githubusercontent.com/ml-mipt/ml-mipt/advanced/homeworks/homework1_three_headed_network/network.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.112.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.112.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1469 (1,4K) [text/plain]\n",
      "Saving to: ‘network.py’\n",
      "\n",
      "network.py          100%[===================>]   1,43K  --.-KB/s    in 0s      \n",
      "\n",
      "2020-03-25 02:42:12 (70,4 MB/s) - ‘network.py’ saved [1469/1469]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#uncomment and run this cell, if you don't have data locally yet.\n",
    "\n",
    "!curl -L https://www.dropbox.com/s/5msc5ix7ndyba10/Train_rev1.csv.tar.gz?dl=1 -o Train_rev1.csv.tar.gz\n",
    "!tar -xvzf ./Train_rev1.csv.tar.gz\n",
    "\n",
    "!wget https://raw.githubusercontent.com/ml-mipt/ml-mipt/advanced/homeworks/homework1_three_headed_network/network.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./Train_rev1.csv\", index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "UuuKIKfrycOH",
    "outputId": "e5de0f94-a4f6-4b51-db80-9d11ddc1db31"
   },
   "outputs": [],
   "source": [
    "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')\n",
    "text_columns = [\"Title\", \"FullDescription\"]\n",
    "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\"]\n",
    "target_column = \"Log1pSalary\"\n",
    "\n",
    "data[categorical_columns] = data[categorical_columns].fillna('NaN') # cast missing values to string \"NaN\"\n",
    "\n",
    "data.sample(3)\n",
    "\n",
    "\n",
    "data_for_autotest = data[-5000:]\n",
    "data = data[:-5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RUWkpd7PycOQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "705it [00:00, 7044.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized:\n",
      "2         mathematical modeller / simulation analyst / o...\n",
      "100002    a successful and high achieving specialist sch...\n",
      "200002    web designer html , css , javascript , photosh...\n",
      "Name: FullDescription, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239768it [00:42, 5633.73it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "# see task above\n",
    "def normalize(text):\n",
    "    text = str(text).lower()\n",
    "    return ' '.join(tokenizer.tokenize(text))\n",
    "    \n",
    "data[text_columns] = data[text_columns].applymap(normalize)\n",
    "\n",
    "print(\"Tokenized:\")\n",
    "print(data[\"FullDescription\"][2::100000])\n",
    "assert data[\"FullDescription\"][2][:50] == 'mathematical modeller / simulation analyst / opera'\n",
    "assert data[\"Title\"][54321] == 'international digital account manager ( german )'\n",
    "\n",
    "# Count how many times does each token occur in both \"Title\" and \"FullDescription\" in total\n",
    "# build a dictionary { token -> it's count }\n",
    "from collections import Counter\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "token_counts = Counter()# <YOUR CODE HERE>\n",
    "for _, row in tqdm(data[text_columns].iterrows()):\n",
    "    for string in row:\n",
    "        token_counts.update(string.split())\n",
    "\n",
    "# hint: you may or may not want to use collections.Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2598827"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_counts.most_common(1)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "colab_type": "code",
    "id": "GiOWbc15ycOb",
    "outputId": "1e807140-5513-4af0-d9a9-9f029059a553"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique tokens : 201127\n",
      "('and', 2598827)\n",
      "('.', 2471477)\n",
      "(',', 2266256)\n",
      "('the', 2036428)\n",
      "('to', 1977039)\n",
      "...\n",
      "('dbms_stats', 1)\n",
      "('dbms_output', 1)\n",
      "('dbms_job', 1)\n",
      "Correct!\n",
      "Vocabulary size: 33795\n",
      "Correct!\n",
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "print(\"Total unique tokens :\", len(token_counts))\n",
    "print('\\n'.join(map(str, token_counts.most_common(n=5))))\n",
    "print('...')\n",
    "print('\\n'.join(map(str, token_counts.most_common()[-3:])))\n",
    "\n",
    "assert token_counts.most_common(1)[0][1] in  range(2500000, 2700000)\n",
    "assert len(token_counts) in range(200000, 210000)\n",
    "print('Correct!')\n",
    "\n",
    "min_count = 10\n",
    "\n",
    "# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\n",
    "tokens = [token for token, count in token_counts.items() if count >= min_count]# <YOUR CODE HERE>\n",
    "# Add a special tokens for unknown and empty words\n",
    "UNK, PAD = \"UNK\", \"PAD\"\n",
    "tokens = [UNK, PAD] + sorted(tokens)\n",
    "print(\"Vocabulary size:\", len(tokens))\n",
    "\n",
    "assert type(tokens) == list\n",
    "assert len(tokens) in range(32000, 35000)\n",
    "assert 'me' in tokens\n",
    "assert UNK in tokens\n",
    "print(\"Correct!\")\n",
    "\n",
    "token_to_id = {token: idx for idx, token in enumerate(tokens)}\n",
    "assert isinstance(token_to_id, dict)\n",
    "assert len(token_to_id) == len(tokens)\n",
    "for tok in tokens:\n",
    "    assert tokens[token_to_id[tok]] == tok\n",
    "\n",
    "print(\"Correct!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JEsLeBjVycOw"
   },
   "outputs": [],
   "source": [
    "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
    "\n",
    "def as_matrix(sequences, max_len=None):\n",
    "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
    "    if isinstance(sequences[0], str):\n",
    "        sequences = list(map(str.split, sequences))\n",
    "        \n",
    "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
    "    \n",
    "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
    "    for i,seq in enumerate(sequences):\n",
    "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
    "        matrix[i, :len(row_ix)] = row_ix\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "colab_type": "code",
    "id": "JiBlPkdKycOy",
    "outputId": "3866b444-1e2d-4d79-d429-fecc6d8e02a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines:\n",
      "engineering systems analyst\n",
      "hr assistant\n",
      "senior ec & i engineer\n",
      "\n",
      "Matrix:\n",
      "[[10705 29830  2143     1     1]\n",
      " [14875  2817     1     1     1]\n",
      " [27345 10107    15 15069 10702]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Lines:\")\n",
    "print('\\n'.join(data[\"Title\"][::100000].values), end='\\n\\n')\n",
    "print(\"Matrix:\")\n",
    "print(as_matrix(data[\"Title\"][::100000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "DpOlBp7ZycO6",
    "outputId": "30a911f2-7d35-4cb5-8991-60457b1e8bac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DictVectorizer(dtype=<class 'numpy.float32'>, separator='=', sort=True,\n",
       "               sparse=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# we only consider top-1k most frequent companies to minimize memory usage\n",
    "top_companies, top_counts = zip(*Counter(data['Company']).most_common(1000))\n",
    "recognized_companies = set(top_companies)\n",
    "data[\"Company\"] = data[\"Company\"].apply(lambda comp: comp if comp in recognized_companies else \"Other\")\n",
    "\n",
    "categorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\n",
    "categorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yk4jmtAYycO8"
   },
   "source": [
    "### The deep learning part\n",
    "\n",
    "Once we've learned to tokenize the data, let's design a machine learning experiment.\n",
    "\n",
    "As before, we won't focus too much on validation, opting for a simple train-test split.\n",
    "\n",
    "__To be completely rigorous,__ we've comitted a small crime here: we used the whole data for tokenization and vocabulary building. A more strict way would be to do that part on training set only. You may want to do that and measure the magnitude of changes.\n",
    "\n",
    "\n",
    "#### Here comes the simple one-headed network from the seminar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "TngLcWA0ycO_",
    "outputId": "6731b28c-07b1-41dc-9574-f76b01785bba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size =  191814\n",
      "Validation size =  47954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_val = train_test_split(data, test_size=0.2, random_state=42)\n",
    "data_train.index = range(len(data_train))\n",
    "data_val.index = range(len(data_val))\n",
    "\n",
    "print(\"Train size = \", len(data_train))\n",
    "print(\"Validation size = \", len(data_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2PXuKgOSycPB"
   },
   "outputs": [],
   "source": [
    "def make_batch(data, max_len=None, word_dropout=0):\n",
    "    \"\"\"\n",
    "    Creates a keras-friendly dict from the batch data.\n",
    "    :param word_dropout: replaces token index with UNK_IX with this probability\n",
    "    :returns: a dict with {'title' : int64[batch, title_max_len]\n",
    "    \"\"\"\n",
    "    batch = {}\n",
    "    batch[\"Title\"] = as_matrix(data[\"Title\"].values, max_len)\n",
    "    batch[\"FullDescription\"] = as_matrix(data[\"FullDescription\"].values, max_len)\n",
    "    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1))\n",
    "    \n",
    "    if word_dropout != 0:\n",
    "        batch[\"FullDescription\"] = apply_word_dropout(batch[\"FullDescription\"], 1. - word_dropout)\n",
    "    \n",
    "    if target_column in data.columns:\n",
    "        batch[target_column] = data[target_column].values\n",
    "    \n",
    "    return batch\n",
    "\n",
    "def apply_word_dropout(matrix, keep_prop, replace_with=UNK_IX, pad_ix=PAD_IX,):\n",
    "    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1 - keep_prop])\n",
    "    dropout_mask &= matrix != pad_ix\n",
    "    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "colab_type": "code",
    "id": "I6LpEQf0ycPD",
    "outputId": "e3520cae-fba1-46cc-a216-56287b6e4929"
   },
   "outputs": [],
   "source": [
    "a = make_batch(data_train[:3], max_len=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But to start with let's build the simple model using only the part of the data. Let's create the baseline solution using only the description part (so it should definetely fit into the Sequential model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will need these to make it simple\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "class Reorder(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.permute((0, 2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate minibatches we will use simple pyton generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_minibatches(data, batch_size=256, shuffle=True, cycle=False, **kwargs):\n",
    "    \"\"\" iterates minibatches of data in random order \"\"\"\n",
    "    while True:\n",
    "        indices = np.arange(len(data))\n",
    "        if shuffle:\n",
    "            indices = np.random.permutation(indices)\n",
    "\n",
    "        for start in range(0, len(indices), batch_size):\n",
    "            batch = make_batch(data.iloc[indices[start : start + batch_size]], **kwargs)\n",
    "            target = batch.pop(target_column)\n",
    "            yield batch, target\n",
    "        \n",
    "        if not cycle: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iterate_minibatches(data_train, 3)\n",
    "batch, target = next(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is some startup code:\n",
    "n_tokens=len(tokens)\n",
    "n_cat_features=len(categorical_vectorizer.vocabulary_)\n",
    "hid_size=64\n",
    "simple_model = nn.Sequential()\n",
    "\n",
    "simple_model.add_module('emb', nn.Embedding(num_embeddings=n_tokens, embedding_dim=hid_size))\n",
    "simple_model.add_module('reorder', Reorder())\n",
    "simple_model.add_module('conv1', nn.Conv1d(\n",
    "    in_channels=hid_size,\n",
    "    out_channels=hid_size,\n",
    "    kernel_size=2)\n",
    "                       )\n",
    "simple_model.add_module('relu1', nn.ReLU())\n",
    "simple_model.add_module('adapt_avg_pool', nn.AdaptiveAvgPool1d(output_size=1))\n",
    "simple_model.add_module('flatten1', Flatten())\n",
    "simple_model.add_module('linear1', nn.Linear(in_features=hid_size, out_features=1))\n",
    "# <YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remember!__ We are working with regression problem and predicting only one number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1427],\n",
       "        [0.0208],\n",
       "        [0.1746]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try this to check your model. `torch.long` tensors are required for nn.Embedding layers.\n",
    "simple_model(torch.tensor(batch['FullDescription'], dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 292)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['FullDescription'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3746"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch['Categorical'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Title': array([[ 9177, 11346,     1],\n",
       "        [ 8114, 27445,  1569],\n",
       "        [24093,  9239,  9438]], dtype=int32),\n",
       " 'FullDescription': array([[ 2120, 21721, 14083,  2569, 12466,   965,  9177, 11346, 33198,\n",
       "         13963, 21556, 11453, 15402, 32735,  6554, 30762, 29894,   965,\n",
       "         17041, 23415, 33209,  2120, 11082, 10479, 30080,   167,    80,\n",
       "         23248,  2995,  3771,   156,  3512, 15402, 12420,   167, 30411,\n",
       "         29406,  9177, 11346, 33079,  3607, 23863, 25867, 12466,   891,\n",
       "         24000, 15755,  2166,  7792,  9177, 28350,   156, 31946, 13769,\n",
       "          2166, 23963,  1297, 10479,   156, 27401, 30762, 15476,  7400,\n",
       "          2166, 26320,  8894,  2166, 18659, 30411, 32773,  7303,  4353,\n",
       "          8922,  2166, 19802,   156, 10781,  7303,  2166, 12877,  2545,\n",
       "         32019, 15479,  4466,  3190,  1297, 32735,   156, 19802,   156,\n",
       "         28255,  2166, 10471, 18850,  5183,   167, 30762, 30985,   156,\n",
       "         19181,  2166, 25668, 30411, 10262, 21405, 21593, 18850,  5183,\n",
       "         30578, 32735,  2151,  2166, 15800, 30842,  2662, 13455,  2151,\n",
       "          2166, 32773, 21753,   167, 16973, 31823, 30762,  8381, 33198,\n",
       "         32735,    32, 32504,    80,  5030,    63, 28850,  3837, 23579,\n",
       "          2166, 10778, 30487,  2545, 10683,  1297,  1894,  9177,  5859,\n",
       "          2166,  5183, 12466, 33642,  2386, 12466, 30411,  9177, 11346,\n",
       "         30762,  3607, 29406,   156, 33635, 27736,  6314,  8756, 30407,\n",
       "         33635, 14109, 30411, 12426, 28011,   891, 13446, 17203, 15402,\n",
       "         14921,  2166, 22982,  2166, 33331, 30762, 32504,    80,  5030,\n",
       "         28850, 15402, 32735,  9000, 24240, 11453, 15402,  9177, 18850,\n",
       "         11295, 17203, 15402, 27401, 30149,   156, 15353,  2166, 32735,\n",
       "          2142, 30842,   167, 28255, 19217, 11453,   156, 19802, 18850,\n",
       "           156,  9177,  1554,   156, 10168, 30411, 29406,  9177, 32735,\n",
       "         11346,  5196, 11413,   965, 26682, 21405,    80,  3771, 15187,\n",
       "         33635,  2545,  2120,  2039,   156, 30135,  3189,  9177, 11346,\n",
       "         18235, 30762, 16729,   965, 12578, 30501, 30080, 15402, 30411,\n",
       "          9000, 21405,  9177, 18850, 21784, 32735,  9000, 30436,  2395,\n",
       "         21133, 30762,     0,     0,  2892, 15824, 22680,   167,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1],\n",
       "        [30762, 24244, 30226,   195,  1465, 29566,  8497, 33198, 14446,\n",
       "         17768, 21405, 15414, 30226,  5142, 12769, 17041,  8130,  2166,\n",
       "         25850, 30762, 13153, 24624,   167, 24556, 28011, 20145, 21425,\n",
       "           156, 29227,  1461,  2166, 30226, 11453, 33403,  3607,  2120,\n",
       "          1532, 12466, 30512, 21425,  3512, 26324,   167, 23844, 30226,\n",
       "         21784,  5124,  5722, 11453, 16289,  8252,     0,  6777, 33079,\n",
       "          3607, 25722,  7338, 15707, 31812, 16836,   461,   167,    80,\n",
       "         22907, 15707, 15479, 30762,    80, 22907,  1650,   307, 32803,\n",
       "           167, 33747,  9888, 30762, 30411, 14446, 32435, 21405,  2389,\n",
       "         32718,  8091, 25001,   156, 32718,  2545, 31571, 30762, 25845,\n",
       "         30762,  1894,  5223,   167, 15187, 33635,  9526, 21084, 14251,\n",
       "         12769,   965,  7252, 33209,    80, 33331,  8430, 31693, 33635,\n",
       "         14109,  3682, 31804, 21556, 30512, 21337,   191, 30512, 16658,\n",
       "         32637, 21870, 23459,  2662, 33468,   167, 30895,   167,  6681,\n",
       "           195, 16679,   195,  8134,    80,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1],\n",
       "        [21972, 10065, 19559,  3512,  6347, 14083,  2120, 11320, 22759,\n",
       "         21721, 12466,   965, 24093,  9239, 33198, 30411, 25864,  2166,\n",
       "         18664, 12466, 30411,  7239, 21405, 18577,   156,  4978, 21084,\n",
       "         25898, 30762,   156,  9438,  5722,   195, 15557, 24114,   167,\n",
       "         30411, 29406,  5221, 33079,  3607, 17576,  2166, 29574,   965,\n",
       "          8715, 30080, 10781, 29406,  8715, 32976,  6945, 33198,  2166,\n",
       "         15358, 24569,   156, 14229,  2166, 26653,   156, 32033, 18664,\n",
       "          2166,  8114, 26836,   167, 30487, 33079,  1973,  3607, 25867,\n",
       "         12466, 17576, 30411, 30288,   195,  3909, 23971,  2166,  4938,\n",
       "          9000, 29154, 12466, 30512,  4938, 29170, 21972,  6347, 16289,\n",
       "           965, 12578, 30501,  2166, 24086,  7239,  6835, 33010,  2545,\n",
       "         31615, 13428,   965, 22737, 21405, 13717, 15402, 30422,  9438,\n",
       "         27169,   167, 11562,  2166, 24240, 11453, 21405,  7238, 17437,\n",
       "         32605,   195,  9438,  5722, 31729, 12769, 30411, 30288, 28810,\n",
       "         30578, 30762,  6919, 33198,   965, 24240,  1041, 30762, 12110,\n",
       "         18659,   156, 29153, 23137,  2166,  7069, 26188,  2796,   167,\n",
       "         24240, 11453, 30762,  8988,  2166,  6802,  4938, 29154,   156,\n",
       "         17567, 30411, 30288,  3913, 23971,  2166,  8704, 14446, 24569,\n",
       "         24114, 32976,  7323,  8649, 32698, 30762, 15476,  8114, 26836,\n",
       "         16289, 11068,   167, 11295, 15999,  2166, 11567,  6806, 16289,\n",
       "         11068,   167, 30512, 16289,  2120, 21721,   156, 12466, 30411,\n",
       "         26139, 15538,   156, 30762, 24244, 30411, 17572, 21405,   965,\n",
       "         28537,  4938, 29170, 15402, 30512, 27169,   167,  1545,  9289,\n",
       "         30512, 31993, 16289,  3512, 15402, 30411, 31726, 17120,   167,\n",
       "          3454, 26399, 21595, 21684, 15402, 30411, 31523,  2166,  5196,\n",
       "         21595, 23971,  2389, 12769,  5223, 33010,  2545,  8091,   965,\n",
       "         25791,  2166, 10423, 30762, 33306, 15402, 30411, 31523, 32976,\n",
       "         32718, 33079, 10636, 30762,  7280, 33635, 12426, 33642, 25855,\n",
       "          9888, 30762, 30411, 14446, 32435, 21405,  2389, 30512,  5238,\n",
       "          2007,  3607, 23441,   167, 15187, 33635, 14109, 21084, 13861,\n",
       "         21103, 33209,   774,  8430, 31693, 33642,  2386, 14083, 21084,\n",
       "          3682, 29406,  4978, 32718, 33079, 16973, 33642,  8949, 21556,\n",
       "         12054, 12466, 12924, 21715]], dtype=int32),\n",
       " 'Categorical': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now simple training pipeline (it's commented because we've already done that in class. No need to do it again)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from IPython.display import clear_output\n",
    "# from random import sample\n",
    "\n",
    "# epochs = 1\n",
    "\n",
    "# model = simple_model\n",
    "# opt = torch.optim.Adam(model.parameters())\n",
    "# loss_func = nn.MSELoss()\n",
    "\n",
    "# history = []\n",
    "# for epoch_num in range(epochs):\n",
    "#     for idx, (batch, target) in enumerate(iterate_minibatches(data_train)):\n",
    "#         # Preprocessing the batch data and target\n",
    "#         batch = torch.tensor(batch['FullDescription'], dtype=torch.long)\n",
    "\n",
    "#         target = torch.tensor(target)\n",
    "\n",
    "\n",
    "#         predictions = model(batch)\n",
    "#         predictions = predictions.view(predictions.size(0))\n",
    "\n",
    "#         loss = loss_func(predictions, target)# <YOUR CODE HERE>\n",
    "\n",
    "#         # train with backprop\n",
    "#         loss.backward()\n",
    "#         opt.step()\n",
    "#         opt.zero_grad()\n",
    "#         # <YOUR CODE HERE>\n",
    "\n",
    "#         history.append(loss.data.numpy())\n",
    "#         if (idx+1)%10==0:\n",
    "#             clear_output(True)\n",
    "#             plt.plot(history,label='loss')\n",
    "#             plt.legend()\n",
    "#             plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3\n"
     ]
    }
   ],
   "source": [
    "def f(l):\n",
    "    a, b, c = l\n",
    "    print(a, b, c)\n",
    "    \n",
    "f([1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual homework starts here\n",
    "__Your ultimate task is to code the three headed network described on the picture below.__ \n",
    "To make it closer to the real world, please store the network code in file `network.py` in this directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0eI5h9UMycPF"
   },
   "source": [
    "#### Architecture\n",
    "\n",
    "Our main model consists of three branches:\n",
    "* Title encoder\n",
    "* Description encoder\n",
    "* Categorical features encoder\n",
    "\n",
    "We will then feed all 3 branches into one common network that predicts salary.\n",
    "\n",
    "<img src=\"https://github.com/yandexdataschool/nlp_course/raw/master/resources/w2_conv_arch.png\" width=600px>\n",
    "\n",
    "This clearly doesn't fit into PyTorch __Sequential__ interface. To build such a network, one will have to use [__PyTorch nn.Module API__](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'network' from '/home/belsawan/Documents/ML_hw/semestr_2/network.py'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-run this cell if you updated the file with network source code\n",
    "import imp\n",
    "imp.reload(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import tqdm\n",
    "\n",
    "class ThreeInputsNet_2(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_tokens, n_cat_features, concat_number_of_features, hid_size=64):\n",
    "        \n",
    "        super(ThreeInputsNet_2, self).__init__()\n",
    "        \n",
    "        #print(hid_size)\n",
    "        \n",
    "        self.title_emb = nn.Embedding(n_tokens, embedding_dim=hid_size)\n",
    "        self.title_conv = nn.Conv1d(in_channels=hid_size, out_channels=hid_size, kernel_size=2)\n",
    "        self.title_relu = nn.ReLU()\n",
    "        self.title = nn.AdaptiveAvgPool1d(output_size=1)\n",
    "        \n",
    "        self.full_emb = nn.Embedding(n_tokens, embedding_dim=hid_size)\n",
    "        self.full_conv = nn.Conv1d(in_channels=hid_size, out_channels=hid_size, kernel_size=2)\n",
    "        self.full_relu = nn.ReLU()\n",
    "        self.full = nn.AdaptiveAvgPool1d(output_size=1)\n",
    "        \n",
    "        #self.category_emb = nn.Embedding(n_cat_features, embedding_dim=hid_size*2)\n",
    "        self.category = nn.Linear(in_features=n_cat_features, out_features=hid_size)\n",
    "\n",
    "\n",
    "        # Example for the final layers (after the concatenation)\n",
    "        self.inter_dense = nn.Linear(in_features=concat_number_of_features, out_features=hid_size*2)\n",
    "        self.final_dense = nn.Linear(in_features=hid_size*2, out_features=1)\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, whole_input):\n",
    "        input1, input2, input3 = whole_input\n",
    "        \n",
    "        #print(input1)\n",
    "        \n",
    "        title_beg = self.title_emb(input1).permute((0, 2, 1))\n",
    "        title = self.title(self.title_relu(self.title_conv(title_beg)))\n",
    "        \n",
    "        full_beg = self.full_emb(input2).permute((0, 2, 1))\n",
    "        full = self.full(self.full_relu(self.full_conv(full_beg)))       \n",
    "        \n",
    "        category = self.category(input3)\n",
    "        \n",
    "        #print(title.size())\n",
    "        \n",
    "        #print(full.size())\n",
    "        \n",
    "        #print(category.size())\n",
    "        \n",
    "        concatenated = torch.cat(\n",
    "            [\n",
    "            title.view(title.size(0), -1),\n",
    "            full.view(full.size(0), -1),\n",
    "            category.view(category.size(0), -1)\n",
    "            ],\n",
    "            dim=1)\n",
    "        #print(concatenated)\n",
    "        \n",
    "        pre_out = self.inter_dense(concatenated)\n",
    "        out = self.final_dense(pre_out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ThreeInputsNet_2(\n",
    "    n_tokens=len(tokens),\n",
    "    n_cat_features=len(categorical_vectorizer.vocabulary_),\n",
    "    concat_number_of_features=192\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_batch, _ = next(iterate_minibatches(data_train, 3))\n",
    "testing_batch = [\n",
    "    torch.tensor(testing_batch['Title'], dtype=torch.long),\n",
    "    torch.tensor(testing_batch['FullDescription'], dtype=torch.long),\n",
    "    torch.tensor(testing_batch['Categorical'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0582],\n",
       "        [0.0988],\n",
       "        [0.0426]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(testing_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seems fine!\n"
     ]
    }
   ],
   "source": [
    "assert model(testing_batch).shape == torch.Size([3, 1])\n",
    "assert model(testing_batch).dtype == torch.float32\n",
    "print('Seems fine!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train the network for a while (100 batches would be fine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "history = []\n",
    "\n",
    "for idx, (batch, target) in enumerate(iterate_minibatches(data_train)):\n",
    "    # Preprocessing the batch data and target\n",
    "    \n",
    "    input_batch = [torch.tensor(batch['Title'], dtype=torch.long), torch.tensor(batch['FullDescription'], dtype=torch.long), torch.tensor(batch['Categorical'])]\n",
    "\n",
    "    target = torch.tensor(target)\n",
    "\n",
    "    predictions = model(input_batch)\n",
    "    predictions = predictions.view(predictions.size(0))\n",
    "\n",
    "    loss = loss_func(predictions, target)\n",
    "\n",
    "    # train with backprop\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    history.append(loss.data.numpy())\n",
    "    if (idx+1)%10==0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history,label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    if idx == 30:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to evaluate the model it can be switched to `eval` state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ThreeInputsNet_2(\n",
       "  (title_emb): Embedding(33795, 64)\n",
       "  (title_conv): Conv1d(64, 64, kernel_size=(2,), stride=(1,))\n",
       "  (title_relu): ReLU()\n",
       "  (title): AdaptiveAvgPool1d(output_size=1)\n",
       "  (full_emb): Embedding(33795, 64)\n",
       "  (full_conv): Conv1d(64, 64, kernel_size=(2,), stride=(1,))\n",
       "  (full_relu): ReLU()\n",
       "  (full): AdaptiveAvgPool1d(output_size=1)\n",
       "  (category): Linear(in_features=3746, out_features=64, bias=True)\n",
       "  (inter_dense): Linear(in_features=192, out_features=128, bias=True)\n",
       "  (final_dense): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission(model, data, batch_size=256, name=\"\", three_inputs_mode=True, **kw):\n",
    "    squared_error = abs_error = num_samples = 0.0\n",
    "    output_list = []\n",
    "    for batch_x, batch_y in iterate_minibatches(data, batch_size=batch_size, shuffle=False, **kw):\n",
    "        if three_inputs_mode:\n",
    "            batch = [\n",
    "                torch.tensor(batch_x['Title'], dtype=torch.long),\n",
    "                torch.tensor(batch_x['FullDescription'], dtype=torch.long),\n",
    "                torch.tensor(batch_x['Categorical'])\n",
    "            ]\n",
    "        else:\n",
    "            batch = torch.tensor(batch_x['FullDescription'], dtype=torch.long)\n",
    "\n",
    "        batch_pred = model(batch)[:, 0].detach().numpy()\n",
    "        \n",
    "        output_list.append((list(batch_pred), list(batch_y)))\n",
    "        \n",
    "        squared_error += np.sum(np.square(batch_pred - batch_y))\n",
    "        abs_error += np.sum(np.abs(batch_pred - batch_y))\n",
    "        num_samples += len(batch_y)\n",
    "    \n",
    "    print(\"%s results:\" % (name or \"\"))\n",
    "    print(\"Mean square error: %.5f\" % (squared_error / num_samples))\n",
    "    print(\"Mean absolute error: %.5f\" % (abs_error / num_samples))\n",
    "    \n",
    "\n",
    "    batch_pred = [c for x in output_list for c in x[0]]\n",
    "    batch_y = [c for x in output_list for c in x[1]]\n",
    "    output_df = pd.DataFrame(list(zip(batch_pred, batch_y)), columns=['batch_pred', 'batch_y'])\n",
    "    output_df.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission results:\n",
      "Mean square error: 1.23545\n",
      "Mean absolute error: 0.93423\n",
      "Submission file generated\n"
     ]
    }
   ],
   "source": [
    "generate_submission(model, data_for_autotest, name='Submission')\n",
    "print('Submission file generated')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__To hand in this homework, please upload `network.py` file with code and `submission.csv` to the google form.__"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Day_3_CNN_for_texts.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
